{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Climate Pattern Modeling with Hidden Markov Model  \n",
    "\n",
    "**Water Programming: A Collaborative Research Blog (Fitting HMMs: Background and Methods)**  \n",
    "https://waterprogramming.wordpress.com/2018/07/03/fitting-hidden-markov-models-part-i-background-and-methods/  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Statements  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions Definition  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Stationary Distribution from Transition Distribution  \n",
    "\n",
    "**Markov Chains: Stationary Distributions**  \n",
    "https://www.stat.berkeley.edu/~mgoldman/Section0220.pdf  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stationary_distribution(transition_distribution):\n",
    "    num_states = transition_distribution.shape[0]\n",
    "    \n",
    "    delta = np.empty((num_states, num_states))\n",
    "    delta_i = np.empty((num_states, num_states))\n",
    "    stationary_distribution = np.empty(num_states)\n",
    "    \n",
    "    for i in range(num_states - 1):\n",
    "        delta[i] = transition_distribution[:, i]\n",
    "        delta[i, i] = delta[i, i] - 1\n",
    "    \n",
    "    delta[num_states - 1] = np.ones(num_states)\n",
    "    \n",
    "    for i in range(num_states):\n",
    "        delta_i[:, :] = delta\n",
    "        delta_i[:, i] = np.concatenate((np.zeros(num_states - 1), np.ones(1)))\n",
    "        \n",
    "        # ref: https://www.geeksforgeeks.org/how-to-calculate-the-determinant-of-a-matrix-using-numpy/\n",
    "        stationary_distribution[i] = np.linalg.det(delta_i) / np.linalg.det(delta)\n",
    "        \n",
    "    return stationary_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viterbi Algorithm Implementation  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(observations, transition_distribution, emission_means, emission_std_devs):\n",
    "    num_observations = observations.shape[0]\n",
    "    num_states = transition_distribution.shape[0]\n",
    "    \n",
    "    initial_distribution = stationary_distribution(transition_distribution)\n",
    "    \n",
    "    likelihood_previous = np.empty(num_states)\n",
    "    likelihood_current = np.empty(num_states)\n",
    "    \n",
    "    previous_node = np.full((num_states, num_observations), -1)\n",
    "    \n",
    "    for i in range(num_states):\n",
    "        # ref: https://docs.scipy.org/doc/scipy/reference/reference/generated/scipy.stats.norm.html\n",
    "        # ref: https://www.kite.com/python/docs/scipy.stats.norm.pdf\n",
    "        likelihood_previous[i] = np.log(initial_distribution[i]) + np.log(norm.pdf(x=observations[0], loc=emission_means[i], scale=emission_std_devs[i]))\n",
    "    \n",
    "    for i in range(1, num_observations):\n",
    "        for j in range(num_states):\n",
    "            likelihood_current[j] = likelihood_previous[0] + np.log(transition_distribution[0, j]) + np.log(norm.pdf(x=observations[i], loc=emission_means[j], scale=emission_std_devs[j]))\n",
    "            previous_node[j, i] = 0\n",
    "            \n",
    "            for k in range(1, num_states):\n",
    "                likelihood = likelihood_previous[k] + np.log(transition_distribution[k, j]) + np.log(norm.pdf(x=observations[i], loc=emission_means[j], scale=emission_std_devs[j]))\n",
    "                \n",
    "                if likelihood > likelihood_current[j]:\n",
    "                    likelihood_current[j] = likelihood\n",
    "                    previous_node[j, i] = k\n",
    "        \n",
    "        likelihood_previous[:] = likelihood_current\n",
    "    \n",
    "    estimated_states_sequence = [likelihood_current.argmax()]\n",
    "    \n",
    "    for i in range(num_observations - 1):\n",
    "        estimated_states_sequence.append(previous_node[estimated_states_sequence[i], num_observations - (i + 1)])\n",
    "        \n",
    "    estimated_states_sequence.reverse()\n",
    "    return estimated_states_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baum-Welch Learning Algorithm Implementation  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(observations, transition_distribution, emission_means, emission_std_devs):\n",
    "    num_observations = observations.shape[0]\n",
    "    num_states = transition_distribution.shape[0]\n",
    "    \n",
    "    initial_distribution = stationary_distribution(transition_distribution)\n",
    "    \n",
    "    forward_matrix = np.zeros((num_states, num_observations))\n",
    "    \n",
    "    for i in range(num_states):\n",
    "        forward_matrix[i, 0] = initial_distribution[i] * norm.pdf(x=observations[0], loc=emission_means[i], scale=emission_std_devs[i])\n",
    "    \n",
    "    forward_matrix[:, 0] = forward_matrix[:, 0] / np.sum(forward_matrix[:, 0])\n",
    "    \n",
    "    for i in range(1, num_observations):\n",
    "        for j in range(num_states):\n",
    "            for k in range(num_states):\n",
    "                forward_matrix[j, i] = forward_matrix[j, i] + forward_matrix[k, i - 1] * transition_distribution[k, j] * norm.pdf(x=observations[i], loc=emission_means[j], scale=emission_std_devs[j])\n",
    "        \n",
    "        forward_matrix[:, i] = forward_matrix[:, i] / np.sum(forward_matrix[:, i])\n",
    "    \n",
    "    return forward_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(observations, transition_distribution, emission_means, emission_std_devs):\n",
    "    num_observations = observations.shape[0]\n",
    "    num_states = transition_distribution.shape[0]\n",
    "    \n",
    "    backward_matrix = np.zeros((num_states, num_observations))\n",
    "    backward_matrix[:, num_observations - 1] = np.ones(num_states)\n",
    "    \n",
    "    for i in range(1, num_observations):\n",
    "        for j in range(num_states):\n",
    "            for k in range(num_states):\n",
    "                backward_matrix[j, num_observations - (i + 1)] = backward_matrix[j, num_observations - (i + 1)] + backward_matrix[k, num_observations - i] * transition_distribution[j, k] * norm.pdf(x=observations[num_observations - i], loc=emission_means[k], scale=emission_std_devs[k])\n",
    "        \n",
    "        backward_matrix[:, num_observations - (i + 1)] = backward_matrix[:, num_observations - (i + 1)] / np.sum(backward_matrix[:, num_observations - (i + 1)])\n",
    "    \n",
    "    return backward_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baum_welch_learning(observations, transition_distribution, emission_means, emission_std_devs, num_epochs):\n",
    "    num_observations = observations.shape[0]\n",
    "    num_states = transition_distribution.shape[0]\n",
    "    \n",
    "    responsibility_profile_for_states = np.empty((num_states, num_observations))\n",
    "    responsibility_profile_for_transitions = np.empty((num_states, num_states, num_observations - 1))\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        forward_matrix = forward(observations, transition_distribution, emission_means, emission_std_devs)\n",
    "        backward_matrix = backward(observations, transition_distribution, emission_means, emission_std_devs)\n",
    "        \n",
    "        for i in range(num_observations):\n",
    "            for j in range(num_states):\n",
    "                responsibility_profile_for_states[j, i] = forward_matrix[j, i] * backward_matrix[j, i]\n",
    "        \n",
    "        responsibility_profile_for_states = responsibility_profile_for_states / np.sum(responsibility_profile_for_states, axis=0)\n",
    "        \n",
    "        for i in range(num_observations - 1):\n",
    "            for j in range(num_states):\n",
    "                for k in range(num_states):\n",
    "                    responsibility_profile_for_transitions[j, k, i] = forward_matrix[j, i] * transition_distribution[j, k] * norm.pdf(x=observations[i + 1], loc=emission_means[k], scale=emission_std_devs[k]) * backward_matrix[k, i + 1]\n",
    "        \n",
    "        responsibility_profile_for_transitions = responsibility_profile_for_transitions / np.sum(responsibility_profile_for_transitions, axis=(0, 1))\n",
    "        \n",
    "        transition_distribution = np.sum(responsibility_profile_for_transitions, axis=-1)\n",
    "        transition_distribution = transition_distribution / np.sum(transition_distribution, axis=1)[:, None]\n",
    "        \n",
    "        emission_means = np.sum(responsibility_profile_for_states * observations, axis=1) / np.sum(responsibility_profile_for_states, axis=1)\n",
    "        emission_std_devs = np.sqrt(np.sum(responsibility_profile_for_states * np.power(np.tile(observations, (num_states, 1)) - emission_means.reshape(num_states, 1), 2), axis=1) / np.sum(responsibility_profile_for_states, axis=1))\n",
    "    \n",
    "    return transition_distribution, emission_means, emission_std_devs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentations  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Rainfall Estimates Data from `data.txt`  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./inputdir/data.txt', 'r') as observations_file:\n",
    "    observations = observations_file.read().split('\\n')\n",
    "\n",
    "observations = np.array([float(observation) for observation in observations if observation != ''])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting HMM Parameters from `parameters.txt`  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./inputdir/parameters.txt', 'r') as parameters_file:\n",
    "    parameters = parameters_file.read().split('\\n')\n",
    "\n",
    "parameters = [parameter_line for parameter_line in parameters if parameter_line != '']\n",
    "\n",
    "num_states = int(parameters[0])\n",
    "\n",
    "transition_distribution = np.empty((num_states, num_states))\n",
    "\n",
    "for i in range(num_states):\n",
    "    transition_distribution[i] = np.array(parameters[i + 1].split('\\t'), dtype=np.float64)\n",
    "    \n",
    "gaussian_distribution_means = np.array(parameters[num_states + 1].split('\\t'), dtype=np.float64)\n",
    "gaussian_distribution_std_devs = np.sqrt(np.array(parameters[num_states + 2].split('\\t'), dtype=np.float64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating States Sequence with Provided Parameters by Solving Decoding Problem  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./outputdir'):\n",
    "    os.makedirs('./outputdir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_states_sequence = viterbi(observations, transition_distribution, gaussian_distribution_means, gaussian_distribution_std_devs)\n",
    "estimated_states_sequence = ['\"El Nino\"' if estimated_state == 0 else '\"La Nina\"' for estimated_state in estimated_states_sequence]\n",
    "\n",
    "with open('./outputdir/estimated-states-sequence-with-provided-parameters.txt', 'w') as output_file:\n",
    "    output_file.write('\\n'.join(estimated_states_sequence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating HMM Parameters with Baum-Welch Learning Algorithm  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_distribution, gaussian_distribution_means, gaussian_distribution_std_devs = baum_welch_learning(observations, transition_distribution, gaussian_distribution_means, gaussian_distribution_std_devs, num_epochs=5)\n",
    "\n",
    "num_states = transition_distribution.shape[0]\n",
    "learned_parameters = [str(num_states)]\n",
    "\n",
    "for i in range(num_states):\n",
    "    learned_parameters.append('\\t'.join(list(map(str, transition_distribution[i].tolist()))))\n",
    "\n",
    "learned_parameters.append('\\t'.join(list(map(str, gaussian_distribution_means.tolist()))))\n",
    "learned_parameters.append('\\t'.join(list(map(str, np.power(gaussian_distribution_std_devs, 2).tolist()))))\n",
    "learned_parameters.append('\\t'.join(list(map(str, stationary_distribution(transition_distribution).tolist()))))\n",
    "\n",
    "with open('./outputdir/learned-parameters.txt', 'w') as output_file:\n",
    "    output_file.write('\\n'.join(learned_parameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating States Sequence with Learned Parameters by Solving Decoding Problem  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_states_sequence = viterbi(observations, transition_distribution, gaussian_distribution_means, gaussian_distribution_std_devs)\n",
    "estimated_states_sequence = ['\"El Nino\"' if estimated_state == 0 else '\"La Nina\"' for estimated_state in estimated_states_sequence]\n",
    "\n",
    "with open('./outputdir/estimated-states-sequence-with-learned-parameters.txt', 'w') as output_file:\n",
    "    output_file.write('\\n'.join(estimated_states_sequence))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
